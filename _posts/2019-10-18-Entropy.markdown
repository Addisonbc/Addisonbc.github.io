---
layout: post
title:  Entropy
---
# Entropy
#blog/article
“Entropy” as a measure of information, is gaining more and more attention nowadays in the study of our brain. It’s also an important concept in another fascinating field - thermodynamics. I believe a lot of people are like me, hearing it first at their high school physics class, and later surprised to find out that it can also measure information. In this post, I am going to explain what entropy is and how it connects with computational neuroscience.

### Basic Idea
- - - -
Intuitively, entropy is said to measure the **degree of disorder**. If a certain amount of gas molecules are at a higher temperature, they tend to move faster, so in a way they have more entropy -is this even correct-???? It might sound counter-intuitive how this single index could describe both thermal system and information system. To my understanding, they connect through another idea - **possibility**.

Let me start with a story first. It’s a famous story in thermodynamics, told by a famous physicist Maxwell. The story is about a little demon “disturbing” the world order. 
Imagine a bunch of gas molecules sitting in two connecting boxes like this.:![](Entropy/bear_sketch@2x.png)
They both contain “hot” molecules and “cold” molecules, hence are at the same temperature. A little demon comes in and opens a tinier door _(one that does not need any energy to open or close)_ in the middle, letting only the cold molecule pass from box A to box B, and hot molecules the other way. So, the box would end up like this, with A being very hot, and B being very cold.
This seriously violates the -second?- law of thermodynamics. Without external -force (做功)-, a cold box cannot heat up a hot box, meaning the process would have stopped when there is even one molecule passing through the door. Beyond that, the disorder of the universe actually decreased! Now we know all the hot molecules are in box A, all the cold molecules are in box B.
Now you see why there’s a quotation mark around “disturbing” - it’s actually disturbing the system by decreasing the disorder! 

This is when the fun thing happens. The reason why the demon has successfully decreased the entropy, is that he input something we could not see into the system - the knowledge of his about which molecules are hot and which ones are cold, in other words, **the information**.

Now I’m going to explain a bit about how those two relates by probability.
Before all the chaos happened, let’s say there were two hot and two cold molecules in each of the boxes, so the entropy would look like this
![](Entropy/bear_sketch@2x.png)
x 2 boxes

But after changing the state, the entropy becomes![](Entropy/bear_sketch@2x.png)

We become more certain about which state the molecules are actually in, there’s higher probability for the lesser states we know the system might be in.


Now where does this leave us for informational entropy?


 (Note that the idea above actually deviate a bit from rigorous physics, but we’re not real physicists, so...)
