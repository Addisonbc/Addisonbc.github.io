<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-10-18T15:14:26-04:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Your awesome title</title><subtitle>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</subtitle><entry><title type="html">Welcome to Jekyll!</title><link href="http://localhost:4000/jekyll/update/2019/10/18/welcome-to-jekyll.html" rel="alternate" type="text/html" title="Welcome to Jekyll!" /><published>2019-10-18T14:54:21-04:00</published><updated>2019-10-18T14:54:21-04:00</updated><id>http://localhost:4000/jekyll/update/2019/10/18/welcome-to-jekyll</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2019/10/18/welcome-to-jekyll.html">&lt;p&gt;You’ll find this post in your &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run &lt;code class=&quot;highlighter-rouge&quot;&gt;jekyll serve&lt;/code&gt;, which launches a web server and auto-regenerates your site when a file is updated.&lt;/p&gt;

&lt;p&gt;Jekyll requires blog post files to be named according to the following format:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;YEAR-MONTH-DAY-title.MARKUP&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Where &lt;code class=&quot;highlighter-rouge&quot;&gt;YEAR&lt;/code&gt; is a four-digit number, &lt;code class=&quot;highlighter-rouge&quot;&gt;MONTH&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;DAY&lt;/code&gt; are both two-digit numbers, and &lt;code class=&quot;highlighter-rouge&quot;&gt;MARKUP&lt;/code&gt; is the file extension representing the format used in the file. After that, include the necessary front matter. Take a look at the source for this post to get an idea about how it works.&lt;/p&gt;

&lt;p&gt;Jekyll also offers powerful support for code snippets:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;puts&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Hi, &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;#{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'Tom'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#=&amp;gt; prints 'Hi, Tom' to STDOUT.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Check out the &lt;a href=&quot;https://jekyllrb.com/docs/home&quot;&gt;Jekyll docs&lt;/a&gt; for more info on how to get the most out of Jekyll. File all bugs/feature requests at &lt;a href=&quot;https://github.com/jekyll/jekyll&quot;&gt;Jekyll’s GitHub repo&lt;/a&gt;. If you have questions, you can ask them on &lt;a href=&quot;https://talk.jekyllrb.com/&quot;&gt;Jekyll Talk&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><summary type="html">You’ll find this post in your _posts directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run jekyll serve, which launches a web server and auto-regenerates your site when a file is updated.</summary></entry><entry><title type="html">Entropy</title><link href="http://localhost:4000/2019/10/18/Entropy.html" rel="alternate" type="text/html" title="Entropy" /><published>2019-10-18T00:00:00-04:00</published><updated>2019-10-18T00:00:00-04:00</updated><id>http://localhost:4000/2019/10/18/Entropy</id><content type="html" xml:base="http://localhost:4000/2019/10/18/Entropy.html">&lt;h1 id=&quot;entropy&quot;&gt;Entropy&lt;/h1&gt;
&lt;p&gt;#blog/article
“Entropy” as a measure of information, is gaining more and more attention nowadays in the study of our brain. It’s also an important concept in another fascinating field - thermodynamics. I believe a lot of people are like me, hearing it first at their high school physics class, and later surprised to find out that it can also measure information. In this post, I am going to explain what entropy is and how it connects with computational neuroscience.&lt;/p&gt;

&lt;h3 id=&quot;basic-idea&quot;&gt;Basic Idea&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;Intuitively, entropy is said to measure the &lt;strong&gt;degree of disorder&lt;/strong&gt;. If a certain amount of gas molecules are at a higher temperature, they tend to move faster, so in a way they have more entropy -is this even correct-???? It might sound counter-intuitive how this single index could describe both thermal system and information system. To my understanding, they connect through another idea - &lt;strong&gt;possibility&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Let me start with a story first. It’s a famous story in thermodynamics, told by a famous physicist Maxwell. The story is about a little demon “disturbing” the world order. 
Imagine a bunch of gas molecules sitting in two connecting boxes like this.:&lt;img src=&quot;Entropy/bear_sketch@2x.png&quot; alt=&quot;&quot; /&gt;
They both contain “hot” molecules and “cold” molecules, hence are at the same temperature. A little demon comes in and opens a tinier door &lt;em&gt;(one that does not need any energy to open or close)&lt;/em&gt; in the middle, letting only the cold molecule pass from box A to box B, and hot molecules the other way. So, the box would end up like this, with A being very hot, and B being very cold.
This seriously violates the -second?- law of thermodynamics. Without external -force (做功)-, a cold box cannot heat up a hot box, meaning the process would have stopped when there is even one molecule passing through the door. Beyond that, the disorder of the universe actually decreased! Now we know all the hot molecules are in box A, all the cold molecules are in box B.
Now you see why there’s a quotation mark around “disturbing” - it’s actually disturbing the system by decreasing the disorder!&lt;/p&gt;

&lt;p&gt;This is when the fun thing happens. The reason why the demon has successfully decreased the entropy, is that he input something we could not see into the system - the knowledge of his about which molecules are hot and which ones are cold, in other words, &lt;strong&gt;the information&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Now I’m going to explain a bit about how those two relates by probability.
Before all the chaos happened, let’s say there were two hot and two cold molecules in each of the boxes, so the entropy would look like this
&lt;img src=&quot;Entropy/bear_sketch@2x.png&quot; alt=&quot;&quot; /&gt;
x 2 boxes&lt;/p&gt;

&lt;p&gt;But after changing the state, the entropy becomes&lt;img src=&quot;Entropy/bear_sketch@2x.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We become more certain about which state the molecules are actually in, there’s higher probability for the lesser states we know the system might be in.&lt;/p&gt;

&lt;p&gt;Now where does this leave us for informational entropy?&lt;/p&gt;

&lt;p&gt;(Note that the idea above actually deviate a bit from rigorous physics, but we’re not real physicists, so…)&lt;/p&gt;</content><author><name></name></author><summary type="html">Entropy #blog/article “Entropy” as a measure of information, is gaining more and more attention nowadays in the study of our brain. It’s also an important concept in another fascinating field - thermodynamics. I believe a lot of people are like me, hearing it first at their high school physics class, and later surprised to find out that it can also measure information. In this post, I am going to explain what entropy is and how it connects with computational neuroscience.</summary></entry></feed>